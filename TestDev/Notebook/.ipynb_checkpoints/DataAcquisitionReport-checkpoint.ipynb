{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc85f1a",
   "metadata": {},
   "source": [
    "#  Data Acquisition & Data Analyse Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afdaac",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524ed43",
   "metadata": {},
   "source": [
    "Ce notebook constitue le rapport des modules Data Acquisition et Dana Analyse. Ce rapport fait donc office d'explication des modules python. Il permet nottament d'expliquer \n",
    "- le role de chaque module,\n",
    "- les fonctions et les concepts implementés\n",
    "\n",
    "NB : Le code présenté ne constitue pas le code source des module. C'est un code simplifié qui facilite la compréhension des systèmes. Les fonctionnalitées non codés dans ce rapport seront tout de même expliquées et documéntées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3337ba91",
   "metadata": {},
   "source": [
    "Ce notebook est à titre d'explication. Seul les fonctionnalitées essentielles sont présentées, le but étant de à des de fin de compréhension. Les autres fonctionnalitées seront tout de même expliquées et documéntées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1394e",
   "metadata": {},
   "source": [
    "##### download the requierement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5f50cc",
   "metadata": {},
   "source": [
    "Elasticsearch6 package is used but you can also use elastiscsearch (that will be work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c806ccf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install elasticsearch6\\n!pip install pandas\\n!pip install scikit-learn\\n!pip install scipy \\n!pip install plotly\\n!pip install numpy\\n!pip install umap-learn\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install elasticsearch6\n",
    "!pip install pandas\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b2d26",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8a65c",
   "metadata": {},
   "source": [
    "#### Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd82eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca8fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "host='localhost'\n",
    "port = 9200\n",
    "path_data= f'{os.getcwd()}/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2bf647",
   "metadata": {},
   "source": [
    "create a directory for the data that will be save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201b24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path_directory):\n",
    "    if not os.path.exists(path_directory):\n",
    "        os.mkdir(path_directory)\n",
    "create_directory(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baff32e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/eguimard/PycharmProjects/DataStudy/TestDev/Notebook/data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f8c9de",
   "metadata": {},
   "source": [
    "### Connecting To Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f369854",
   "metadata": {},
   "source": [
    "Connect To ElasticSearch Cluster with python-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd36c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch6 import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4658f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch(f'{host}:{port}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dc9f3f",
   "metadata": {},
   "source": [
    "#### Index  for the search :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8215633",
   "metadata": {},
   "outputs": [],
   "source": [
    "index= \"events-20220502\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5b282",
   "metadata": {},
   "source": [
    "### Make a query  on the Elastic Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5bb9a2",
   "metadata": {},
   "source": [
    "here it's a json elastic query wrote in dict python. With this query, we recover all the data where category == 'availability' in the index \"events-20220502\". \n",
    "Here we chose perimeter availability for the report, but it's pretty much the same process for the others perimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb222bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "perimeter =\"availability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ecd09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VM =\"VM1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec035389",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_in_dict ={\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\n",
    "          \"match\": {\n",
    "            \"category\": perimeter\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"match\": {\n",
    "            \"hostname\": VM\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"must_not\": [],\n",
    "      \"should\": []\n",
    "    }\n",
    "  },\n",
    "  \"from\": 0,\n",
    "  \"size\": 1000,\n",
    "  \"sort\": [],\n",
    "  \"aggs\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e389c9",
   "metadata": {},
   "source": [
    "Here we run the query on the cluster. <br>The output correpond to the return of the query. We will name this raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c100b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['took', 'timed_out', '_shards', 'hits'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = client.search(index=index, body=query_in_dict)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a318e5",
   "metadata": {},
   "source": [
    "### Extracting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef551e",
   "metadata": {},
   "source": [
    "Here we will exctract the relevant data drom raw_data for futures analysis. The relevant data are twice : \n",
    "- the system data accesible at raw_data['hits']['hits'][n]['_source']['details']['system']\n",
    "- a list of wanted feature that we can define. Features are accesible at raw_data['hits']['hits'][n]['_source']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb8397",
   "metadata": {},
   "source": [
    "Here we define a list of wanted feature to recover. In our cas we just need 'utctimestamp' for the data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbdcb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wanted_features = ['utctimestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075bc16",
   "metadata": {},
   "source": [
    "the main function of the data extracting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f8e1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctract_relevant_data_from_raw_data(raw_data, list_wanted_features):\n",
    "    \n",
    "    dict_of_list_dict_data = dict()\n",
    "    \n",
    "    for results in raw_data['hits']['hits']:\n",
    "        \n",
    "        # extract system data recursively and append to dict_final\n",
    "        system_data = results['_source']['details']['system']\n",
    "        system_name = list(system_data.keys())[0]\n",
    "        \n",
    "        dict_extracted_data = develop_data_recursively_for_extraction(system_data[system_name])\n",
    "        \n",
    "        # wanted_features extraction\n",
    "        dict_extracted_data = extract_wanted_features(results['_source'], list_wanted_features, dict_extracted_data)\n",
    "\n",
    "        \n",
    "        # append dict_extracted_data to the corresponding list\n",
    "        if system_name not in dict_of_list_dict_data:\n",
    "            dict_of_list_dict_data[system_name] = list()\n",
    "        dict_of_list_dict_data[system_name].append(dict_extracted_data)\n",
    "        \n",
    "    return dict_of_list_dict_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd2904",
   "metadata": {},
   "source": [
    "this function  goes back recursively through dict of dict and create feature name foreach value found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf8c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def develop_data_recursively_for_extraction(current_dict, name_feature=''):\n",
    "\n",
    "    dict_final = dict()\n",
    "\n",
    "    if type(current_dict) is dict:\n",
    "        for key, new_obj in current_dict.items():\n",
    "            dict_final.update(develop_data_recursively_for_extraction(new_obj, f'{name_feature}{key}_'))\n",
    "            # update can delete field. in theory, we don't have twice the same field\n",
    "    else:\n",
    "        dict_final[name_feature[:-1]] = current_dict\n",
    "\n",
    "    return dict_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610fb07",
   "metadata": {},
   "source": [
    "this function allows to extract feature from a list of name : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d532651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wanted_features(current_data, list_wanted_features, dict_extracted_data):\n",
    "\n",
    "    for wanted_feature in list_wanted_features:\n",
    "        dict_extracted_data[wanted_feature] = current_data[wanted_feature]\n",
    "\n",
    "    return dict_extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13f4bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_data = exctract_relevant_data_from_raw_data(raw_data, list_wanted_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a6881",
   "metadata": {},
   "source": [
    "In output we have a dictionnary of list. We will convert these lists to Dataframe : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a6b756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06896ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_list_data_to_dataframe(dict_of_list_data):\n",
    "    dict_df = dict()\n",
    "\n",
    "    for key, list_data in dict_of_list_data.items():\n",
    "        dict_df[key] = pd.DataFrame(list_data)\n",
    "\n",
    "    return dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5895841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dataFrame = transform_list_data_to_dataframe(dict_list_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6e6a9",
   "metadata": {},
   "source": [
    "The name of the dataframes created are the keys of dictionnary : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edaff507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'fsstat', 'cpu', 'network'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_dataFrame.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f58d68",
   "metadata": {},
   "source": [
    "Each DataFrame is related to a system perimeter (in the availability case) like memory, cpu, network..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c78874e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>used_pct</th>\n",
       "      <th>used_bytes</th>\n",
       "      <th>actual_free</th>\n",
       "      <th>actual_used_pct</th>\n",
       "      <th>actual_used_bytes</th>\n",
       "      <th>page_stats_pgsteal_direct_pages</th>\n",
       "      <th>page_stats_pgsteal_kswapd_pages</th>\n",
       "      <th>page_stats_direct_efficiency_pct</th>\n",
       "      <th>page_stats_kswapd_efficiency_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>hugepages_swap_out_pages</th>\n",
       "      <th>hugepages_swap_out_fallback</th>\n",
       "      <th>hugepages_total</th>\n",
       "      <th>hugepages_used_pct</th>\n",
       "      <th>hugepages_used_bytes</th>\n",
       "      <th>hugepages_default_size</th>\n",
       "      <th>hugepages_free</th>\n",
       "      <th>hugepages_surplus</th>\n",
       "      <th>hugepages_reserved</th>\n",
       "      <th>utctimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>938954752</td>\n",
       "      <td>611532800</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>417312768</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T04:58:18.308816+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>938954752</td>\n",
       "      <td>611536896</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>417308672</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T04:58:32.825474+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>938954752</td>\n",
       "      <td>611627008</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>417218560</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T05:03:48.332923+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>938921984</td>\n",
       "      <td>611659776</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>417185792</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T05:04:02.818662+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>938921984</td>\n",
       "      <td>611659776</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>417185792</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T05:04:18.298112+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>943955968</td>\n",
       "      <td>610951168</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>417894400</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T07:52:02.560837+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>943955968</td>\n",
       "      <td>610934784</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>417910784</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T07:50:18.056270+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>943955968</td>\n",
       "      <td>610942976</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>417902592</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T07:50:32.565921+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>943439872</td>\n",
       "      <td>611487744</td>\n",
       "      <td>0.4057</td>\n",
       "      <td>417357824</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T07:53:48.059601+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1028845568</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>943439872</td>\n",
       "      <td>611487744</td>\n",
       "      <td>0.4057</td>\n",
       "      <td>417357824</td>\n",
       "      <td>125</td>\n",
       "      <td>552583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-05T07:54:02.555322+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          total  used_pct  used_bytes  actual_free  actual_used_pct  \\\n",
       "0    1028845568    0.9126   938954752    611532800           0.4056   \n",
       "1    1028845568    0.9126   938954752    611536896           0.4056   \n",
       "2    1028845568    0.9126   938954752    611627008           0.4055   \n",
       "3    1028845568    0.9126   938921984    611659776           0.4055   \n",
       "4    1028845568    0.9126   938921984    611659776           0.4055   \n",
       "..          ...       ...         ...          ...              ...   \n",
       "246  1028845568    0.9175   943955968    610951168           0.4062   \n",
       "247  1028845568    0.9175   943955968    610934784           0.4062   \n",
       "248  1028845568    0.9175   943955968    610942976           0.4062   \n",
       "249  1028845568    0.9170   943439872    611487744           0.4057   \n",
       "250  1028845568    0.9170   943439872    611487744           0.4057   \n",
       "\n",
       "     actual_used_bytes  page_stats_pgsteal_direct_pages  \\\n",
       "0            417312768                              125   \n",
       "1            417308672                              125   \n",
       "2            417218560                              125   \n",
       "3            417185792                              125   \n",
       "4            417185792                              125   \n",
       "..                 ...                              ...   \n",
       "246          417894400                              125   \n",
       "247          417910784                              125   \n",
       "248          417902592                              125   \n",
       "249          417357824                              125   \n",
       "250          417357824                              125   \n",
       "\n",
       "     page_stats_pgsteal_kswapd_pages  page_stats_direct_efficiency_pct  \\\n",
       "0                             552583                                 1   \n",
       "1                             552583                                 1   \n",
       "2                             552583                                 1   \n",
       "3                             552583                                 1   \n",
       "4                             552583                                 1   \n",
       "..                               ...                               ...   \n",
       "246                           552583                                 1   \n",
       "247                           552583                                 1   \n",
       "248                           552583                                 1   \n",
       "249                           552583                                 1   \n",
       "250                           552583                                 1   \n",
       "\n",
       "     page_stats_kswapd_efficiency_pct  ...  hugepages_swap_out_pages  \\\n",
       "0                              0.8723  ...                         0   \n",
       "1                              0.8723  ...                         0   \n",
       "2                              0.8723  ...                         0   \n",
       "3                              0.8723  ...                         0   \n",
       "4                              0.8723  ...                         0   \n",
       "..                                ...  ...                       ...   \n",
       "246                            0.8723  ...                         0   \n",
       "247                            0.8723  ...                         0   \n",
       "248                            0.8723  ...                         0   \n",
       "249                            0.8723  ...                         0   \n",
       "250                            0.8723  ...                         0   \n",
       "\n",
       "     hugepages_swap_out_fallback  hugepages_total  hugepages_used_pct  \\\n",
       "0                              0                0                   0   \n",
       "1                              0                0                   0   \n",
       "2                              0                0                   0   \n",
       "3                              0                0                   0   \n",
       "4                              0                0                   0   \n",
       "..                           ...              ...                 ...   \n",
       "246                            0                0                   0   \n",
       "247                            0                0                   0   \n",
       "248                            0                0                   0   \n",
       "249                            0                0                   0   \n",
       "250                            0                0                   0   \n",
       "\n",
       "     hugepages_used_bytes  hugepages_default_size  hugepages_free  \\\n",
       "0                       0                 2097152               0   \n",
       "1                       0                 2097152               0   \n",
       "2                       0                 2097152               0   \n",
       "3                       0                 2097152               0   \n",
       "4                       0                 2097152               0   \n",
       "..                    ...                     ...             ...   \n",
       "246                     0                 2097152               0   \n",
       "247                     0                 2097152               0   \n",
       "248                     0                 2097152               0   \n",
       "249                     0                 2097152               0   \n",
       "250                     0                 2097152               0   \n",
       "\n",
       "     hugepages_surplus  hugepages_reserved                      utctimestamp  \n",
       "0                    0                   0  2022-05-05T04:58:18.308816+00:00  \n",
       "1                    0                   0  2022-05-05T04:58:32.825474+00:00  \n",
       "2                    0                   0  2022-05-05T05:03:48.332923+00:00  \n",
       "3                    0                   0  2022-05-05T05:04:02.818662+00:00  \n",
       "4                    0                   0  2022-05-05T05:04:18.298112+00:00  \n",
       "..                 ...                 ...                               ...  \n",
       "246                  0                   0  2022-05-05T07:52:02.560837+00:00  \n",
       "247                  0                   0  2022-05-05T07:50:18.056270+00:00  \n",
       "248                  0                   0  2022-05-05T07:50:32.565921+00:00  \n",
       "249                  0                   0  2022-05-05T07:53:48.059601+00:00  \n",
       "250                  0                   0  2022-05-05T07:54:02.555322+00:00  \n",
       "\n",
       "[251 rows x 32 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_dataFrame['memory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcad740",
   "metadata": {},
   "source": [
    "Finnaly we Save the dict dataframe to the path data define at the top of this notebook. The dataframes stores will be use in the Notebook Data Analise : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "907e3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_dict_df_into_directory(dict_df, save_path_directory, extension):\n",
    "\n",
    "    for name_df in dict_df.keys():\n",
    "        try:\n",
    "            dict_df[name_df].to_csv(f'{save_path_directory}/{name_df}.{extension}', index=False)\n",
    "        except Exception as err:  # precisez l'exception\n",
    "            return str(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "756a99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dict_df_into_directory(dict_dataFrame, path_data, extension='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c3fa7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/eguimard/PycharmProjects/DataStudy/TestDev/Notebook/data'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
